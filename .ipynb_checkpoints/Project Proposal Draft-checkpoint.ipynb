{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cc1824",
   "metadata": {},
   "source": [
    "# Project Proposal\n",
    "\n",
    "### Basic Info\n",
    "_____\n",
    " \n",
    "**Title**: Fandom Trends and Pecularities From AO3 Data\n",
    " \n",
    "\n",
    "**Names**: Rebekah Washburn, Noble Ledbetter, Henry Brunisholz\n",
    " \n",
    "\n",
    "**Emails**: Rebekah - u1310114@utah.edu, Nobel - u0967666@utah.edu, Henry - u1276675@utah.edu\n",
    " \n",
    "\n",
    "**UIDs**: Rebekah - u1310114, Nobel - u0967666, Henry - u1276675\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Background and Motivation\n",
    "___\n",
    "\n",
    "The world of fanfiction has been thriving for years. Many popular authors started in fanfiction, and some popular novels like *Fifty Shades of Grey* by E. L. James and *After* by Anna Todd. As the world of fanfiction and fandom has become more mainstream, sites like [Archive of Our Own](https://archiveofourown.org) have held millions of works available for people to enjoy. Both Henry and Rebekah are interested in fanfiction and the data surround these works, and previous projects by individuals to analyze said data. We hope to create something meaningful, like Toastystats' fandom statistics, found [here](https://archiveofourown.org/users/destinationtoast/pseuds/toastystats/works?fandom_id=87791).\n",
    "\n",
    "### Project Objectives\n",
    "___\n",
    "Project objectives can be broken into two main groups:\n",
    "- Questions about the data: How does age rating relate to a fics popularity? How closely connected are varying defintions of popularity (comment count, hit count, kudos count)? How does length relate to popularity? Are there mismatches in \"supply and demand\" where a certain kind of fic is very popular among fans but not produced very frequently by writers? What about the other way around, where writers write a lot of not-so-popular stories? How complicated/readable is the average fanfiction? How does that vary with measurements of popularity?\n",
    "- Data Analysis Skill-development: How do we handle a large data set like the one we found? How do you clean and organize data \"from the wild\" so to speak, as opposed to a class example? How best are any findings displayed using charts and other data visualization tools? How do we determine whether something is a useful question to look into? \n",
    "\n",
    "### Data Description and Acquistion\n",
    "___\n",
    "The data we are analyzing is a dataset collected by reddit user theCodeCat in 2020, who scrapped non-user-restricted fan-works from ArchiveOfOurOwn (AO3). The data is available for download [here](https://www.reddit.com/r/datasets/comments/i254cw/archiveofourown_dataset/).\n",
    "\n",
    "The dataset is 77GB when compressed and 502GB uncompressed, containing data from millions of works on AO3 including:\n",
    "- id\n",
    "- rating\n",
    "- whether it is finished\n",
    "- title\n",
    "- description\n",
    "- current number of chapters\n",
    "- planned number of chapters\n",
    "- language\n",
    "- word count\n",
    "- hit count\n",
    "- comment count (but not the comments themselves)\n",
    "- bookmark count\n",
    "- date published\n",
    "- Authors\n",
    "- Users/Authors work is dedicated to\n",
    "- Series work is a part of if applicable\n",
    "- Tags (warnings, fandoms, relationships, characters, relationship types, generic)\n",
    "- Chapter text\n",
    "\n",
    "### Ethical Considerations\n",
    "___\n",
    "Ethical considerations for the use and analysis of this data are fortunately limited, but not non-existent.\n",
    "\n",
    "First, there is the fact that many fanfic writers do not want their fanfics used for data analysis (or machine learning!) projects, as emphasized by the general uproar on the internet following the revelation that LLM's like ChatGPT were trained on data that included fanfiction published to the internet. Using the dataset collected by theCoolCat mostly avoids this ethical quandry, because theCoolCat was the one who collected unrestricted data and distributed it to the world, it won't change any fanfic writer's experience for us to privately analyze that data.\n",
    "\n",
    "Second, there could be personal or upsetting or sensitive information contained in this data set, such as folks' real names or addresses, personal and private experiences, or simply content not suitable for professional environments like graphic sex scenes. This risk is magnified because the dataset contains the chapter *text* of each fanfiction, meaning that the actual words written in each story in the dataset are included in the dataset itself. But, the risk is minimized because we will not be reading the chapter texts ourselves, rather letting the computer do it and using data analytic techniques to summarize the text/meta-data for each piece of fanfiction.\n",
    "\n",
    "### Data Cleaning and Processing\n",
    "___\n",
    "We will certainly have to do substantial data extraction and cleanup due to the size of the data we have. Thankfully, similar tags in our data (such as words, kudos, and hits) will allow us to simplify some of this extraction. \n",
    "\n",
    "Some challenges we will have to our processing will be sorting through the numerous custom tags (\"freeforms\" in the html). These custom tags are specific to the book and designed by the author, however, since we are focusing more on standardized data (such as word count, genre, and kudos) we will be able to focus on the main data we want and then sort through custom tags as needed.\n",
    "\n",
    "### Exploratory Analysis\n",
    "___\n",
    "We will use scatterplots and bar charts primarily to determine trends in our data, like how kudos relate to the completeness of the fanfic or if rating increases based on the length of the fanfic. Using the altair or seaborn programs, we can also use a third indicator to visualize other trends within our data. \n",
    "\n",
    "### Analysis Methodology\n",
    "___\n",
    "\n",
    "\n",
    "### Project Schedule\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac640a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
