{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d806bbf",
   "metadata": {},
   "source": [
    "### Creating readability scores\n",
    "\n",
    "To compute readability, we will calculate the average sentence length and average word length\n",
    "\n",
    "\n",
    "**Note: Due to file size issues, we are only computing readability for a small selection of the total sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9200a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\readi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word and sentence lengths calculated and stored successfully.\n",
      "Average word length for storyId 63: 3.6958509142053444\n",
      "Average sentence length for storyId 63: 12.740112994350282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"reduced_chapter_text.csv\")\n",
    "\n",
    "# Function to calculate average word length\n",
    "def avg_word_length(text):\n",
    "    words = word_tokenize(text)\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    return sum(word_lengths) / len(word_lengths) if len(word_lengths) > 0 else 0\n",
    "\n",
    "# Function to calculate average sentence length\n",
    "def avg_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_lengths = [len(sent.split()) for sent in sentences]\n",
    "    return sum(sentence_lengths) / len(sentence_lengths) if len(sentence_lengths) > 0 else 0\n",
    "\n",
    "# Calculate average word length and average sentence length for each storyId\n",
    "averages = data.groupby('storyId').apply(lambda x: pd.Series({\n",
    "    'avg_word_length': x['text'].apply(avg_word_length).mean(),\n",
    "    'avg_sentence_length': x['text'].apply(avg_sentence_length).mean()\n",
    "}))\n",
    "\n",
    "# Store averages for later use\n",
    "averages.to_csv(\"story_averages.csv\")\n",
    "\n",
    "print(\"Average word and sentence lengths calculated and stored successfully.\")\n",
    "\n",
    "\n",
    "# Calculate average word length and average sentence length for storyId 63, to check functionality\n",
    "averages = data[data['storyId'] == 63]\n",
    "avg_word_length_63 = averages['text'].apply(avg_word_length).mean()\n",
    "avg_sentence_length_63 = averages['text'].apply(avg_sentence_length).mean()\n",
    "\n",
    "# Print the results of test\n",
    "print(\"Average word length for storyId 63:\", avg_word_length_63)\n",
    "print(\"Average sentence length for storyId 63:\", avg_sentence_length_63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9773dce",
   "metadata": {},
   "source": [
    "### Finding correlation between readability and popularity\n",
    "\n",
    "Here, we compute the correlation between our two notions of readability and our four notions of popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad7cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Average Word Length, Average Sentence Length, and Popularity Metrics:\n",
      "                     avg_word_length  avg_sentence_length      hits     kudos  \\\n",
      "avg_word_length             1.000000             0.178947  0.007897  0.004962   \n",
      "avg_sentence_length         0.178947             1.000000  0.013776  0.009300   \n",
      "hits                        0.007897             0.013776  1.000000  0.935438   \n",
      "kudos                       0.004962             0.009300  0.935438  1.000000   \n",
      "comments                   -0.002383             0.005629  0.818407  0.749074   \n",
      "bookmarks                   0.008979             0.009061  0.926273  0.943758   \n",
      "\n",
      "                     comments  bookmarks  \n",
      "avg_word_length     -0.002383   0.008979  \n",
      "avg_sentence_length  0.005629   0.009061  \n",
      "hits                 0.818407   0.926273  \n",
      "kudos                0.749074   0.943758  \n",
      "comments             1.000000   0.844439  \n",
      "bookmarks            0.844439   1.000000  \n",
      "\n",
      "Correlation between avg_word_length and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and hits: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and kudos: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and comments: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and bookmarks: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and hits: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and kudos: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and comments: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and bookmarks: Weak or no correlation\n",
      "\n",
      "Correlation between hits and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between hits and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between hits and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between hits and comments: Strong positive correlation\n",
      "\n",
      "Correlation between hits and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between kudos and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between kudos and hits: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and comments: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between comments and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between comments and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between comments and hits: Strong positive correlation\n",
      "\n",
      "Correlation between comments and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between comments and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between bookmarks and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between bookmarks and hits: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and comments: Strong positive correlation\n"
     ]
    }
   ],
   "source": [
    "# Load the stored averages\n",
    "averages = pd.read_csv(\"story_averages.csv\")\n",
    "\n",
    "# Load the popularity metrics\n",
    "popularity_metrics = pd.read_csv(\"reduced_project_info.csv\")\n",
    "\n",
    "# Merge the averages and popularity metrics on storyId\n",
    "merged_data = pd.merge(popularity_metrics, averages, left_on='id', right_on='storyId')\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = merged_data[['avg_word_length', 'avg_sentence_length', 'hits', 'kudos', 'comments', 'bookmarks']].corr()\n",
    "\n",
    "print(\"Correlation between Average Word Length, Average Sentence Length, and Popularity Metrics:\")\n",
    "print(correlations)\n",
    "\n",
    "# Define a function to interpret correlation values\n",
    "def interpret_correlation(correlation):\n",
    "    if correlation > 0.7:\n",
    "        return \"Strong positive correlation\"\n",
    "    elif correlation > 0.3:\n",
    "        return \"Moderate positive correlation\"\n",
    "    elif correlation > -0.3:\n",
    "        return \"Weak or no correlation\"\n",
    "    elif correlation > -0.7:\n",
    "        return \"Moderate negative correlation\"\n",
    "    else:\n",
    "        return \"Strong negative correlation\"\n",
    "\n",
    "# Iterate over each pair of variables in the correlation matrix and interpret the correlation\n",
    "for column1 in correlations.columns:\n",
    "    for column2 in correlations.columns:\n",
    "        if column1 != column2:\n",
    "            correlation = correlations.loc[column1, column2]\n",
    "            interpretation = interpret_correlation(correlation)\n",
    "            print(f\"\\nCorrelation between {column1} and {column2}: {interpretation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8863fc2",
   "metadata": {},
   "source": [
    "### Result: Readability does not predict popularity\n",
    "\n",
    "There is a weak or no correlation between our measures of readability and our measures of popularity, indicating that popularity can not be predicted by readability. Somewhat surprisingly, there is also no strong correlation between our two measures of readability however, there is a strong positive correlation between the different notions of popularity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7490db",
   "metadata": {},
   "source": [
    "### Finding the most and least readable works\n",
    "\n",
    "Here we find and print the ID numbers for the work with the longest average sentence length, the shortest average sentence length, the longest average word length, and the shortest average word length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2146bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work with Maximum Average Word Length:\n",
      "storyId                103753.000000\n",
      "avg_word_length             5.356742\n",
      "avg_sentence_length        11.072289\n",
      "Name: 4144, dtype: float64\n",
      "\n",
      "Work with Minimum Average Word Length:\n",
      "storyId                82910.000000\n",
      "avg_word_length            2.720848\n",
      "avg_sentence_length        8.631579\n",
      "Name: 3374, dtype: float64\n",
      "\n",
      "Work with Maximum Average Sentence Length:\n",
      "storyId                32287.000000\n",
      "avg_word_length            3.894379\n",
      "avg_sentence_length      741.500000\n",
      "Name: 1293, dtype: float64\n",
      "\n",
      "Work with Minimum Average Sentence Length:\n",
      "storyId                41540.000000\n",
      "avg_word_length            3.281768\n",
      "avg_sentence_length        4.100000\n",
      "Name: 1671, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the stored averages\n",
    "averages = pd.read_csv(\"story_averages.csv\")\n",
    "\n",
    "# Find the work with the maximum and minimum average word length\n",
    "max_avg_word_length = averages.loc[averages['avg_word_length'].idxmax()]\n",
    "min_avg_word_length = averages.loc[averages['avg_word_length'].idxmin()]\n",
    "\n",
    "# Find the work with the maximum and minimum average sentence length\n",
    "max_avg_sentence_length = averages.loc[averages['avg_sentence_length'].idxmax()]\n",
    "min_avg_sentence_length = averages.loc[averages['avg_sentence_length'].idxmin()]\n",
    "\n",
    "print(\"Work with Maximum Average Word Length:\")\n",
    "print(max_avg_word_length)\n",
    "\n",
    "print(\"\\nWork with Minimum Average Word Length:\")\n",
    "print(min_avg_word_length)\n",
    "\n",
    "print(\"\\nWork with Maximum Average Sentence Length:\")\n",
    "print(max_avg_sentence_length)\n",
    "\n",
    "print(\"\\nWork with Minimum Average Sentence Length:\")\n",
    "print(min_avg_sentence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5b5e2",
   "metadata": {},
   "source": [
    "### Tag analysis with NLP\n",
    "Project contains analysis of AO3 tags using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee69e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>storyId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>Tag Name</th>\n",
       "      <th>Tag Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Viggo Mortensen/Orlando Bloom</td>\n",
       "      <td>relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Lord of the Rings RPF</td>\n",
       "      <td>fandom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Sean Bean</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>4189</td>\n",
       "      <td>11615</td>\n",
       "      <td>1891</td>\n",
       "      <td>Brendon Urie</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>4190</td>\n",
       "      <td>11615</td>\n",
       "      <td>1892</td>\n",
       "      <td>Ryan Ross</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>4191</td>\n",
       "      <td>11615</td>\n",
       "      <td>1893</td>\n",
       "      <td>Jon Walker</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>4192</td>\n",
       "      <td>11615</td>\n",
       "      <td>1894</td>\n",
       "      <td>Zack Hall</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>4193</td>\n",
       "      <td>11615</td>\n",
       "      <td>187</td>\n",
       "      <td>First Time</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4194 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  storyId  tagId                       Tag Name      Tag Type\n",
       "0              0        3      1      No Archive Warnings Apply       warning\n",
       "1              1        3      2                          Other      category\n",
       "2              2        3      3  Viggo Mortensen/Orlando Bloom  relationship\n",
       "3              3        3      4          Lord of the Rings RPF        fandom\n",
       "4              4        3      5                      Sean Bean     character\n",
       "...          ...      ...    ...                            ...           ...\n",
       "4189        4189    11615   1891                   Brendon Urie     character\n",
       "4190        4190    11615   1892                      Ryan Ross     character\n",
       "4191        4191    11615   1893                     Jon Walker     character\n",
       "4192        4192    11615   1894                      Zack Hall     character\n",
       "4193        4193    11615    187                     First Time       generic\n",
       "\n",
       "[4194 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "\n",
    "data_tags = pd.read_csv('small_story_tags.csv')\n",
    "data_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b650b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warning' 'category' 'relationship' 'fandom' 'character' 'generic'] , 6\n",
      "\n",
      "['No Archive Warnings Apply' 'Other' 'Viggo Mortensen/Orlando Bloom' ...\n",
      " 'Ryan Ross' 'Jon Walker' 'Zack Hall'] , 1892\n"
     ]
    }
   ],
   "source": [
    "print(data_tags['Tag Type'].unique(),',',data_tags['Tag Type'].nunique())\n",
    "print()\n",
    "print(data_tags['Tag Name'].unique(),',',data_tags['Tag Name'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8e6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 34   0   0  61   0   0]\n",
      " [ 18 125   5  11  36   0]\n",
      " [  3   5  88  15   0   2]\n",
      " [  7   0   9 218   0   4]\n",
      " [  2  66   2   1  13   0]\n",
      " [  0   0   0   0   0 114]]\n",
      "0.7056019070321812\n"
     ]
    }
   ],
   "source": [
    "tag_names = data_tags['Tag Name'].to_list()\n",
    "tag_names = [str(tag) for tag in tag_names]\n",
    "tag_names_str = ' '.join(tag_names)\n",
    "\n",
    "CountV = CountVectorizer()\n",
    "CountV_tag_names = CountV.fit_transform(tag_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(CountV_tag_names, data_tags['Tag Type'], train_size=0.8)\n",
    "\n",
    "tags_classifier = MultinomialNB()\n",
    "tags_classifier.fit(X_train,y_train)\n",
    "tags_pred = tags_classifier.predict(X_test)\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_true = y_test, y_pred = tags_pred))\n",
    "print(accuracy_score(y_test, tags_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec29ce",
   "metadata": {},
   "source": [
    "### Result: \n",
    "- The natural language learning model is able to predict the correct tag type based on the tag name with about 70% accuracy. Often, it would confuse \"category\" tags with \"character\" tags or \"fandoms\" with \"warnings\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62953d85",
   "metadata": {},
   "source": [
    "### % Of Restricted Works\n",
    "\n",
    "To find the % of works that are restricted by their authors and thus not in our sample, we will go through the whole list of works and count the number of restricted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d931b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of restricted works: 4.4 %\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"not_reduced_project_info.csv\")\n",
    "\n",
    "# Calculate the percentage of restricted works\n",
    "restricted_percentage = (data['restricted'].sum() / len(data)) * 100\n",
    "\n",
    "print(\"Percentage of restricted works:\", round(restricted_percentage, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f3b4d",
   "metadata": {},
   "source": [
    "### Result: Restriction is Uncommon\n",
    "\n",
    "Less than 5% of works in our sample are restricted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
