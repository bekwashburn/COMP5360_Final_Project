{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0018d600",
   "metadata": {},
   "source": [
    "### Creating readability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2609fe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\readi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word and sentence lengths calculated and stored successfully.\n",
      "Average word length for storyId 63: 3.6958509142053444\n",
      "Average sentence length for storyId 63: 12.740112994350282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"reduced_chapter_text.csv\")\n",
    "\n",
    "# Function to calculate average word length\n",
    "def avg_word_length(text):\n",
    "    words = word_tokenize(text)\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    return sum(word_lengths) / len(word_lengths) if len(word_lengths) > 0 else 0\n",
    "\n",
    "# Function to calculate average sentence length\n",
    "def avg_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_lengths = [len(sent.split()) for sent in sentences]\n",
    "    return sum(sentence_lengths) / len(sentence_lengths) if len(sentence_lengths) > 0 else 0\n",
    "\n",
    "# Calculate average word length and average sentence length for each storyId\n",
    "averages = data.groupby('storyId').apply(lambda x: pd.Series({\n",
    "    'avg_word_length': x['text'].apply(avg_word_length).mean(),\n",
    "    'avg_sentence_length': x['text'].apply(avg_sentence_length).mean()\n",
    "}))\n",
    "\n",
    "# Store averages for later use\n",
    "averages.to_csv(\"story_averages.csv\")\n",
    "\n",
    "print(\"Average word and sentence lengths calculated and stored successfully.\")\n",
    "\n",
    "\n",
    "# Calculate average word length and average sentence length for storyId 100\n",
    "averages = data[data['storyId'] == 63]\n",
    "avg_word_length_63 = averages['text'].apply(avg_word_length).mean()\n",
    "avg_sentence_length_63 = averages['text'].apply(avg_sentence_length).mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Average word length for storyId 63:\", avg_word_length_63)\n",
    "print(\"Average sentence length for storyId 63:\", avg_sentence_length_63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08568a64",
   "metadata": {},
   "source": [
    "### Finding correlation between readability and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0598bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Average Word Length, Average Sentence Length, and Popularity Metrics:\n",
      "                     avg_word_length  avg_sentence_length      hits     kudos  \\\n",
      "avg_word_length             1.000000             0.178947  0.007897  0.004962   \n",
      "avg_sentence_length         0.178947             1.000000  0.013776  0.009300   \n",
      "hits                        0.007897             0.013776  1.000000  0.935438   \n",
      "kudos                       0.004962             0.009300  0.935438  1.000000   \n",
      "comments                   -0.002383             0.005629  0.818407  0.749074   \n",
      "bookmarks                   0.008979             0.009061  0.926273  0.943758   \n",
      "\n",
      "                     comments  bookmarks  \n",
      "avg_word_length     -0.002383   0.008979  \n",
      "avg_sentence_length  0.005629   0.009061  \n",
      "hits                 0.818407   0.926273  \n",
      "kudos                0.749074   0.943758  \n",
      "comments             1.000000   0.844439  \n",
      "bookmarks            0.844439   1.000000  \n",
      "\n",
      "Correlation between avg_word_length and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and hits: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and kudos: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and comments: Weak or no correlation\n",
      "\n",
      "Correlation between avg_word_length and bookmarks: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and hits: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and kudos: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and comments: Weak or no correlation\n",
      "\n",
      "Correlation between avg_sentence_length and bookmarks: Weak or no correlation\n",
      "\n",
      "Correlation between hits and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between hits and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between hits and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between hits and comments: Strong positive correlation\n",
      "\n",
      "Correlation between hits and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between kudos and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between kudos and hits: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and comments: Strong positive correlation\n",
      "\n",
      "Correlation between kudos and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between comments and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between comments and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between comments and hits: Strong positive correlation\n",
      "\n",
      "Correlation between comments and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between comments and bookmarks: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and avg_word_length: Weak or no correlation\n",
      "\n",
      "Correlation between bookmarks and avg_sentence_length: Weak or no correlation\n",
      "\n",
      "Correlation between bookmarks and hits: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and kudos: Strong positive correlation\n",
      "\n",
      "Correlation between bookmarks and comments: Strong positive correlation\n"
     ]
    }
   ],
   "source": [
    "# Load the stored averages\n",
    "averages = pd.read_csv(\"story_averages.csv\")\n",
    "\n",
    "# Load the popularity metrics\n",
    "popularity_metrics = pd.read_csv(\"reduced_project_info.csv\")\n",
    "\n",
    "# Merge the averages and popularity metrics on storyId\n",
    "merged_data = pd.merge(popularity_metrics, averages, left_on='id', right_on='storyId')\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = merged_data[['avg_word_length', 'avg_sentence_length', 'hits', 'kudos', 'comments', 'bookmarks']].corr()\n",
    "\n",
    "print(\"Correlation between Average Word Length, Average Sentence Length, and Popularity Metrics:\")\n",
    "print(correlations)\n",
    "\n",
    "# Define a function to interpret correlation values\n",
    "def interpret_correlation(correlation):\n",
    "    if correlation > 0.7:\n",
    "        return \"Strong positive correlation\"\n",
    "    elif correlation > 0.3:\n",
    "        return \"Moderate positive correlation\"\n",
    "    elif correlation > -0.3:\n",
    "        return \"Weak or no correlation\"\n",
    "    elif correlation > -0.7:\n",
    "        return \"Moderate negative correlation\"\n",
    "    else:\n",
    "        return \"Strong negative correlation\"\n",
    "\n",
    "# Iterate over each pair of variables in the correlation matrix and interpret the correlation\n",
    "for column1 in correlations.columns:\n",
    "    for column2 in correlations.columns:\n",
    "        if column1 != column2:\n",
    "            correlation = correlations.loc[column1, column2]\n",
    "            interpretation = interpret_correlation(correlation)\n",
    "            print(f\"\\nCorrelation between {column1} and {column2}: {interpretation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb4bdc",
   "metadata": {},
   "source": [
    "### Finding the most and least readable works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dbefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work with Maximum Average Word Length:\n",
      "storyId                103753.000000\n",
      "avg_word_length             5.356742\n",
      "avg_sentence_length        11.072289\n",
      "Name: 4144, dtype: float64\n",
      "\n",
      "Work with Minimum Average Word Length:\n",
      "storyId                82910.000000\n",
      "avg_word_length            2.720848\n",
      "avg_sentence_length        8.631579\n",
      "Name: 3374, dtype: float64\n",
      "\n",
      "Work with Maximum Average Sentence Length:\n",
      "storyId                32287.000000\n",
      "avg_word_length            3.894379\n",
      "avg_sentence_length      741.500000\n",
      "Name: 1293, dtype: float64\n",
      "\n",
      "Work with Minimum Average Sentence Length:\n",
      "storyId                41540.000000\n",
      "avg_word_length            3.281768\n",
      "avg_sentence_length        4.100000\n",
      "Name: 1671, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the stored averages\n",
    "averages = pd.read_csv(\"story_averages.csv\")\n",
    "\n",
    "# Find the work with the maximum and minimum average word length\n",
    "max_avg_word_length = averages.loc[averages['avg_word_length'].idxmax()]\n",
    "min_avg_word_length = averages.loc[averages['avg_word_length'].idxmin()]\n",
    "\n",
    "# Find the work with the maximum and minimum average sentence length\n",
    "max_avg_sentence_length = averages.loc[averages['avg_sentence_length'].idxmax()]\n",
    "min_avg_sentence_length = averages.loc[averages['avg_sentence_length'].idxmin()]\n",
    "\n",
    "print(\"Work with Maximum Average Word Length:\")\n",
    "print(max_avg_word_length)\n",
    "\n",
    "print(\"\\nWork with Minimum Average Word Length:\")\n",
    "print(min_avg_word_length)\n",
    "\n",
    "print(\"\\nWork with Maximum Average Sentence Length:\")\n",
    "print(max_avg_sentence_length)\n",
    "\n",
    "print(\"\\nWork with Minimum Average Sentence Length:\")\n",
    "print(min_avg_sentence_length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
